{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "japanese_vectorize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mashyko/NLP_BERT_Transformers/blob/master/japanese_vectorize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN6uefvAag94",
        "colab_type": "text"
      },
      "source": [
        "# word2vec、fastTextを用いた日本語単語のベクトル表現の実装\n",
        "\n",
        "日本語の単語をword2vecもしくはfastTextを使用してベクトル化して、単語間の類似度を検証\n",
        "\n",
        "「つくりながら学ぶ! PyTorchによる発展ディープラーニング」（小川雄太郎、マイナビ出版 ）」で提供されているコードを使用させていただきました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BxEUZI0ag9_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "使用するMecabおよびデータを用意します\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxciiOwEP_mJ",
        "colab_type": "code",
        "outputId": "68cc52f3-26f2-4c5d-df60-41b25c777d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdSgyo2RQBPV",
        "colab_type": "code",
        "outputId": "c1289127-a17e-44de-df6f-ce0d0c2cdbc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mecab-config --dicdir\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/x86_64-linux-gnu/mecab/dic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4UV2e2_QIbU",
        "colab_type": "code",
        "outputId": "4ea120b8-980e-4951-8c08-cb84cb149a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!cat /etc/mecabrc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ";\n",
            "; Configuration file of MeCab\n",
            ";\n",
            "; $Id: mecabrc.in,v 1.3 2006/05/29 15:36:08 taku-ku Exp $;\n",
            ";\n",
            "dicdir = /var/lib/mecab/dic/debian\n",
            "\n",
            "; userdic = /home/foo/bar/user.dic\n",
            "\n",
            "; output-format-type = wakati\n",
            "; input-buffer-size = 8192\n",
            "\n",
            "; node-format = %m\\n\n",
            "; bos-format = %S\\n\n",
            "; eos-format = EOS\\n\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpLIAg7Tag-A",
        "colab_type": "text"
      },
      "source": [
        "文書を読み込んで、分かち書き、データセット作成\n",
        "\n",
        "前処理と分かち書きをし、最後にデータセットを作成する部分を実装\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJUwbguag-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 単語分割にはMecab＋NEologdを使用\n",
        "import MeCab\n",
        "\n",
        "m_t = MeCab.Tagger('-Owakati -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
        "\n",
        "def tokenizer_mecab(text):\n",
        "    text = m_t.parse(text)  # これでスペースで単語が区切られる\n",
        "    ret = text.strip().split()  # スペース部分で区切ったリストに変換\n",
        "    return ret\n",
        "\n",
        "\n",
        "\n",
        "# 前処理として正規化をする関数を定義\n",
        "import re\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 改行、半角スペース、全角スペースを削除\n",
        "    text = re.sub('\\r', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('　', '', text)\n",
        "    text = re.sub(' ', '', text)\n",
        "\n",
        "    # 数字文字の一律「0」化\n",
        "    text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# 前処理とMecabの単語分割を合わせた関数を定義する\n",
        "\n",
        "\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)  # 前処理の正規化\n",
        "    ret = tokenizer_mecab(text)  # Mecabの単語分割\n",
        "\n",
        "    return ret\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5d1A8LEQ2Lj",
        "colab_type": "code",
        "outputId": "5f4f7ed6-76f9-4df8-954a-bbe369b97011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVZruqkMag-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "\n",
        "# tsvやcsvデータを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "# 文章とラベルの両方に用意します\n",
        "\n",
        "max_length = 25\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing,\n",
        "                            use_vocab=True, lower=True, include_lengths=True, batch_first=True, fix_length=max_length)\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "\n",
        "# フォルダ「data」から各tsvファイルを読み込みます\n",
        "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='/content/drive/My Drive/data/tsv/', train='train.tsv',\n",
        "    validation='val.tsv', test='test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsc7s6gQag-J",
        "colab_type": "text"
      },
      "source": [
        " 単語のベクトル化：word2vec \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of_r3O9XYPqc",
        "colab_type": "text"
      },
      "source": [
        "以下の日本語のfasttextの学習済みベクトルをダウンロードします。\n",
        "\n",
        "https://www.nlp.ecei.tohoku.ac.jp/~m-suzuki/bert-japanese/BERT-base_mecab-ipadic-char-4k_whole-word-mask.tar.xz\n",
        "\n",
        "My Drive/data/に解凍・展開してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbJRtjAxevuO",
        "colab_type": "code",
        "outputId": "2df07a86-6efa-4b51-9c05-e22a4ad30f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# 事前インストール\n",
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.11.14)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.14 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.14.14)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.14->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.14->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Ov9TB1ag-Q",
        "colab_type": "code",
        "outputId": "e6bdfd8f-1ba7-4fbd-f58f-f91375e2f4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# そのままではtorchtextで読み込めないので、gensimライブラリを使用して、\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# 一度gensimライブラリで読み込んで、word2vecのformatで保存する\n",
        "model = KeyedVectors.load_word2vec_format(\n",
        "    '/content/drive/My Drive/data/entity_vector.model.bin', binary=True)\n",
        "\n",
        "# Word2Vecのformatで保存し直します\n",
        "\n",
        "#保存（時間がかかります、10分弱）\n",
        "model.wv.save_word2vec_format('./japanese_word2vec_vectors.vec')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0LItpGag-X",
        "colab_type": "code",
        "outputId": "d528ad2c-6d5c-4525-f7b4-cf687dc40215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# torchtextで単語ベクトルとして読み込みます\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "japanese_word2vec_vectors = Vectors(\n",
        "    name='./japanese_word2vec_vectors.vec')\n",
        "\n",
        "# 単語ベクトルの中身を確認します\n",
        "print(\"1単語を表現する次元数：\", japanese_word2vec_vectors.dim)\n",
        "print(\"単語数：\", len(japanese_word2vec_vectors.itos))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1015474 [00:00<?, ?it/s]Skipping token b'1015474' with 1-dimensional vector [b'200']; likely a header\n",
            "100%|█████████▉| 1015447/1015474 [01:10<00:00, 14586.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1単語を表現する次元数： 200\n",
            "単語数： 1015474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFoP9b8Eag-a",
        "colab_type": "code",
        "outputId": "c8460f0d-7a22-4586-a410-775e25545696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# ベクトル化したバージョンのボキャブラリーを作成します\n",
        "TEXT.build_vocab(train_ds, vectors=japanese_word2vec_vectors, min_freq=1)\n",
        "\n",
        "# ボキャブラリーのベクトルを確認します\n",
        "print(TEXT.vocab.vectors.shape)  # 49個の単語が200次元のベクトルで表現されている\n",
        "TEXT.vocab.vectors\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([49, 200])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 2.6023, -2.6357, -2.5822,  ...,  0.6953, -1.4977,  1.4752],\n",
              "        ...,\n",
              "        [-2.8353,  2.5609, -0.5348,  ...,  0.4602,  1.4669, -2.1255],\n",
              "        [-1.5885,  0.1614, -0.6029,  ..., -1.7545, -1.2462,  2.3034],\n",
              "        [-0.0448, -0.1304,  0.0329,  ...,  0.0825, -0.1386,  0.0417]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBxn47ZAag-e",
        "colab_type": "code",
        "outputId": "daa54f32-cefe-4192-fb57-dcfadc6c6a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# ボキャブラリーの単語の順番を確認します\n",
        "TEXT.vocab.stoi\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'0': 18,\n",
              "             '<pad>': 1,\n",
              "             '<unk>': 0,\n",
              "             '、': 7,\n",
              "             '。': 3,\n",
              "             'い': 19,\n",
              "             'いる': 11,\n",
              "             'か': 12,\n",
              "             'から': 20,\n",
              "             'が': 8,\n",
              "             'し': 9,\n",
              "             'する': 21,\n",
              "             'その': 22,\n",
              "             'た': 23,\n",
              "             'て': 13,\n",
              "             'で': 24,\n",
              "             'です': 25,\n",
              "             'と': 2,\n",
              "             'な': 4,\n",
              "             'に': 26,\n",
              "             'に対して': 27,\n",
              "             'の': 5,\n",
              "             'は': 28,\n",
              "             'まし': 29,\n",
              "             'ます': 14,\n",
              "             'を': 10,\n",
              "             'クラス': 30,\n",
              "             'ネガティブ': 31,\n",
              "             'ポジティブ': 32,\n",
              "             'モデル': 33,\n",
              "             'レビュー': 34,\n",
              "             '値': 35,\n",
              "             '分類': 15,\n",
              "             '取り組み': 36,\n",
              "             '商品': 37,\n",
              "             '女性': 38,\n",
              "             '女王': 39,\n",
              "             '好き': 40,\n",
              "             '姫': 41,\n",
              "             '文章': 6,\n",
              "             '本章': 16,\n",
              "             '構築': 42,\n",
              "             '機械学習': 43,\n",
              "             '王': 44,\n",
              "             '王子': 45,\n",
              "             '男性': 46,\n",
              "             '短い': 47,\n",
              "             '自然言語処理': 48,\n",
              "             '評価': 17})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm8eiDDfag-i",
        "colab_type": "code",
        "outputId": "bbdfbbb8-40d3-4322-b381-c86d4c7525cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# 姫 - 女性 + 男性 のベクトルがどれと似ているのか確認してみます\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 姫 - 女性 + 男性\n",
        "tensor_calc = TEXT.vocab.vectors[41] - \\\n",
        "    TEXT.vocab.vectors[38] + TEXT.vocab.vectors[46]\n",
        "\n",
        "# コサイン類似度を計算\n",
        "# dim=0 は0次元目で計算してくださいという指定\n",
        "print(\"女王\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[39], dim=0))\n",
        "print(\"王\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[44], dim=0))\n",
        "print(\"王子\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[45], dim=0))\n",
        "print(\"機械学習\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[43], dim=0))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "女王 tensor(0.3840)\n",
            "王 tensor(0.3669)\n",
            "王子 tensor(0.5489)\n",
            "機械学習 tensor(-0.1404)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A1rCpqtag-o",
        "colab_type": "text"
      },
      "source": [
        "姫 - 女性 + 男性　を計算すると狙った通り、王子がもっとも近い結果になりました"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7neks16hag-q",
        "colab_type": "text"
      },
      "source": [
        "word2vecより進歩したベクトル化手法であるfastTextによる単語のベクトル表現を使用します。\n",
        "\n",
        "日本語の学習モデルを以下のサイトにて公開されているので、使用させていただきます。\n",
        "\n",
        "\n",
        "vector_neologd.zipのダウンロード\n",
        "https://drive.google.com/open?id=0ByFQ96A4DgSPUm9wVWRLdm5qbmc\n",
        "\n",
        "ダウンロードしたら、My Drive/vector_neologd に配置してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SSgCvSXag-u",
        "colab_type": "code",
        "outputId": "694ef470-08de-4a2f-ab43-e0742cb45073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# torchtextで単語ベクトルとして読み込みます\n",
        "# word2vecとは異なり、すぐに読み込めます\n",
        "\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "japanese_fasttext_vectors = Vectors(name='/content/drive/My Drive/data/vector_neologd/model.vec')\n",
        "\n",
        "                                    \n",
        "# 単語ベクトルの中身を確認します\n",
        "print(\"1単語を表現する次元数：\", japanese_fasttext_vectors.dim)\n",
        "print(\"単語数：\", len(japanese_fasttext_vectors.itos))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/351122 [00:00<?, ?it/s]\u001b[ASkipping token b'351122' with 1-dimensional vector [b'300']; likely a header\n",
            "\n",
            "  0%|          | 956/351122 [00:00<00:36, 9555.86it/s]\u001b[A\n",
            "  1%|          | 1769/351122 [00:00<00:38, 9075.90it/s]\u001b[A\n",
            "  1%|          | 2653/351122 [00:00<00:38, 9003.81it/s]\u001b[A\n",
            "  1%|          | 3652/351122 [00:00<00:37, 9278.17it/s]\u001b[A\n",
            "  1%|▏         | 4708/351122 [00:00<00:35, 9627.30it/s]\u001b[A\n",
            "  2%|▏         | 5796/351122 [00:00<00:34, 9969.33it/s]\u001b[A\n",
            "  2%|▏         | 6810/351122 [00:00<00:34, 10018.87it/s]\u001b[A\n",
            "  2%|▏         | 7785/351122 [00:00<00:34, 9935.00it/s] \u001b[A\n",
            "  3%|▎         | 8877/351122 [00:00<00:33, 10210.24it/s]\u001b[A\n",
            "  3%|▎         | 9893/351122 [00:01<00:33, 10194.38it/s]\u001b[A\n",
            "  3%|▎         | 10934/351122 [00:01<00:33, 10255.02it/s]\u001b[A\n",
            "  3%|▎         | 11982/351122 [00:01<00:32, 10318.65it/s]\u001b[A\n",
            "  4%|▎         | 13011/351122 [00:01<00:32, 10308.38it/s]\u001b[A\n",
            "  4%|▍         | 14176/351122 [00:01<00:31, 10674.46it/s]\u001b[A\n",
            "  4%|▍         | 15242/351122 [00:01<00:32, 10392.27it/s]\u001b[A\n",
            "  5%|▍         | 16382/351122 [00:01<00:31, 10673.03it/s]\u001b[A\n",
            "  5%|▍         | 17488/351122 [00:01<00:30, 10784.82it/s]\u001b[A\n",
            "  5%|▌         | 18569/351122 [00:01<00:30, 10769.15it/s]\u001b[A\n",
            "  6%|▌         | 19698/351122 [00:01<00:30, 10919.86it/s]\u001b[A\n",
            "  6%|▌         | 20802/351122 [00:02<00:30, 10953.81it/s]\u001b[A\n",
            "  6%|▌         | 21899/351122 [00:02<00:32, 10186.12it/s]\u001b[A\n",
            "  7%|▋         | 22934/351122 [00:02<00:32, 10232.92it/s]\u001b[A\n",
            "  7%|▋         | 23969/351122 [00:02<00:31, 10265.65it/s]\u001b[A\n",
            "  7%|▋         | 25002/351122 [00:02<00:31, 10248.94it/s]\u001b[A\n",
            "  7%|▋         | 26031/351122 [00:02<00:33, 9695.41it/s] \u001b[A\n",
            "  8%|▊         | 27010/351122 [00:02<00:35, 9242.01it/s]\u001b[A\n",
            "  8%|▊         | 27945/351122 [00:02<00:36, 8931.93it/s]\u001b[A\n",
            "  8%|▊         | 28848/351122 [00:02<00:37, 8680.75it/s]\u001b[A\n",
            "  8%|▊         | 29725/351122 [00:03<00:37, 8634.52it/s]\u001b[A\n",
            "  9%|▊         | 30595/351122 [00:03<00:37, 8521.09it/s]\u001b[A\n",
            "  9%|▉         | 31522/351122 [00:03<00:36, 8731.17it/s]\u001b[A\n",
            "  9%|▉         | 32400/351122 [00:03<00:37, 8574.22it/s]\u001b[A\n",
            "  9%|▉         | 33327/351122 [00:03<00:36, 8769.68it/s]\u001b[A\n",
            " 10%|▉         | 34339/351122 [00:03<00:34, 9135.36it/s]\u001b[A\n",
            " 10%|█         | 35486/351122 [00:03<00:32, 9729.11it/s]\u001b[A\n",
            " 10%|█         | 36627/351122 [00:03<00:30, 10176.87it/s]\u001b[A\n",
            " 11%|█         | 37661/351122 [00:03<00:31, 10100.99it/s]\u001b[A\n",
            " 11%|█         | 38744/351122 [00:03<00:30, 10307.20it/s]\u001b[A\n",
            " 11%|█▏        | 39851/351122 [00:04<00:29, 10524.18it/s]\u001b[A\n",
            " 12%|█▏        | 40991/351122 [00:04<00:28, 10770.54it/s]\u001b[A\n",
            " 12%|█▏        | 42075/351122 [00:04<00:28, 10675.03it/s]\u001b[A\n",
            " 12%|█▏        | 43217/351122 [00:04<00:28, 10887.93it/s]\u001b[A\n",
            " 13%|█▎        | 44346/351122 [00:04<00:27, 11005.04it/s]\u001b[A\n",
            " 13%|█▎        | 45472/351122 [00:04<00:27, 11078.66it/s]\u001b[A\n",
            " 13%|█▎        | 46583/351122 [00:04<00:27, 10935.03it/s]\u001b[A\n",
            " 14%|█▎        | 47720/351122 [00:04<00:27, 11061.73it/s]\u001b[A\n",
            " 14%|█▍        | 48829/351122 [00:04<00:28, 10523.87it/s]\u001b[A\n",
            " 14%|█▍        | 49889/351122 [00:04<00:28, 10492.17it/s]\u001b[A\n",
            " 15%|█▍        | 50943/351122 [00:05<00:30, 9707.24it/s] \u001b[A\n",
            " 15%|█▍        | 51929/351122 [00:05<00:30, 9746.19it/s]\u001b[A\n",
            " 15%|█▌        | 52990/351122 [00:05<00:29, 9989.84it/s]\u001b[A\n",
            " 15%|█▌        | 54021/351122 [00:05<00:29, 10083.32it/s]\u001b[A\n",
            " 16%|█▌        | 55136/351122 [00:05<00:28, 10379.50it/s]\u001b[A\n",
            " 16%|█▌        | 56280/351122 [00:05<00:27, 10674.78it/s]\u001b[A\n",
            " 16%|█▋        | 57355/351122 [00:05<00:28, 10401.15it/s]\u001b[A\n",
            " 17%|█▋        | 58402/351122 [00:05<00:28, 10399.91it/s]\u001b[A\n",
            " 17%|█▋        | 59447/351122 [00:05<00:29, 10030.95it/s]\u001b[A\n",
            " 17%|█▋        | 60474/351122 [00:05<00:28, 10099.95it/s]\u001b[A\n",
            " 18%|█▊        | 61489/351122 [00:06<00:29, 9822.29it/s] \u001b[A\n",
            " 18%|█▊        | 62488/351122 [00:06<00:29, 9870.92it/s]\u001b[A\n",
            " 18%|█▊        | 63479/351122 [00:06<00:29, 9792.98it/s]\u001b[A\n",
            " 18%|█▊        | 64517/351122 [00:06<00:28, 9960.79it/s]\u001b[A\n",
            " 19%|█▊        | 65566/351122 [00:06<00:28, 10111.88it/s]\u001b[A\n",
            " 19%|█▉        | 66705/351122 [00:06<00:27, 10463.43it/s]\u001b[A\n",
            " 19%|█▉        | 67856/351122 [00:06<00:26, 10754.97it/s]\u001b[A\n",
            " 20%|█▉        | 68956/351122 [00:06<00:26, 10826.01it/s]\u001b[A\n",
            " 20%|█▉        | 70043/351122 [00:06<00:25, 10817.95it/s]\u001b[A\n",
            " 20%|██        | 71136/351122 [00:07<00:25, 10849.52it/s]\u001b[A\n",
            " 21%|██        | 72288/351122 [00:07<00:25, 11041.83it/s]\u001b[A\n",
            " 21%|██        | 73421/351122 [00:07<00:24, 11125.61it/s]\u001b[A\n",
            " 21%|██        | 74536/351122 [00:07<00:24, 11119.06it/s]\u001b[A\n",
            " 22%|██▏       | 75650/351122 [00:07<00:25, 10988.36it/s]\u001b[A\n",
            " 22%|██▏       | 76776/351122 [00:07<00:24, 11066.89it/s]\u001b[A\n",
            " 22%|██▏       | 77937/351122 [00:07<00:24, 11222.81it/s]\u001b[A\n",
            " 23%|██▎       | 79061/351122 [00:07<00:24, 11213.45it/s]\u001b[A\n",
            " 23%|██▎       | 80231/351122 [00:07<00:23, 11352.73it/s]\u001b[A\n",
            " 23%|██▎       | 81368/351122 [00:07<00:24, 11152.78it/s]\u001b[A\n",
            " 23%|██▎       | 82485/351122 [00:08<00:24, 11072.31it/s]\u001b[A\n",
            " 24%|██▍       | 83594/351122 [00:08<00:25, 10599.21it/s]\u001b[A\n",
            " 24%|██▍       | 84660/351122 [00:08<00:25, 10512.47it/s]\u001b[A\n",
            " 24%|██▍       | 85732/351122 [00:08<00:25, 10571.36it/s]\u001b[A\n",
            " 25%|██▍       | 86792/351122 [00:08<00:26, 9963.83it/s] \u001b[A\n",
            " 25%|██▌       | 87798/351122 [00:08<00:27, 9495.10it/s]\u001b[A\n",
            " 25%|██▌       | 88759/351122 [00:08<00:28, 9099.52it/s]\u001b[A\n",
            " 26%|██▌       | 89681/351122 [00:08<00:29, 8875.18it/s]\u001b[A\n",
            " 26%|██▌       | 90578/351122 [00:08<00:30, 8523.16it/s]\u001b[A\n",
            " 26%|██▌       | 91445/351122 [00:09<00:30, 8566.17it/s]\u001b[A\n",
            " 26%|██▋       | 92309/351122 [00:09<00:30, 8580.34it/s]\u001b[A\n",
            " 27%|██▋       | 93172/351122 [00:09<00:30, 8545.34it/s]\u001b[A\n",
            " 27%|██▋       | 94079/351122 [00:09<00:29, 8694.11it/s]\u001b[A\n",
            " 27%|██▋       | 95146/351122 [00:09<00:27, 9204.19it/s]\u001b[A\n",
            " 27%|██▋       | 96156/351122 [00:09<00:26, 9454.56it/s]\u001b[A\n",
            " 28%|██▊       | 97112/351122 [00:09<00:26, 9483.69it/s]\u001b[A\n",
            " 28%|██▊       | 98067/351122 [00:09<00:26, 9375.46it/s]\u001b[A\n",
            " 28%|██▊       | 99075/351122 [00:09<00:26, 9574.03it/s]\u001b[A\n",
            " 28%|██▊       | 100069/351122 [00:09<00:25, 9679.52it/s]\u001b[A\n",
            " 29%|██▉       | 101092/351122 [00:10<00:25, 9837.51it/s]\u001b[A\n",
            " 29%|██▉       | 102090/351122 [00:10<00:25, 9877.35it/s]\u001b[A\n",
            " 29%|██▉       | 103147/351122 [00:10<00:24, 10073.79it/s]\u001b[A\n",
            " 30%|██▉       | 104177/351122 [00:10<00:24, 10138.39it/s]\u001b[A\n",
            " 30%|██▉       | 105235/351122 [00:10<00:23, 10265.28it/s]\u001b[A\n",
            " 30%|███       | 106264/351122 [00:10<00:24, 10072.16it/s]\u001b[A\n",
            " 31%|███       | 107279/351122 [00:10<00:24, 10093.78it/s]\u001b[A\n",
            " 31%|███       | 108302/351122 [00:10<00:23, 10131.74it/s]\u001b[A\n",
            " 31%|███       | 109347/351122 [00:10<00:23, 10223.41it/s]\u001b[A\n",
            " 31%|███▏      | 110470/351122 [00:10<00:22, 10505.06it/s]\u001b[A\n",
            " 32%|███▏      | 111552/351122 [00:11<00:22, 10595.49it/s]\u001b[A\n",
            " 32%|███▏      | 112615/351122 [00:11<00:22, 10604.19it/s]\u001b[A\n",
            " 32%|███▏      | 113677/351122 [00:11<00:23, 10123.18it/s]\u001b[A\n",
            " 33%|███▎      | 114780/351122 [00:11<00:22, 10378.68it/s]\u001b[A\n",
            " 33%|███▎      | 115836/351122 [00:11<00:22, 10430.32it/s]\u001b[A\n",
            " 33%|███▎      | 116915/351122 [00:11<00:22, 10534.82it/s]\u001b[A\n",
            " 34%|███▎      | 117972/351122 [00:11<00:23, 9913.83it/s] \u001b[A\n",
            " 34%|███▍      | 118973/351122 [00:11<00:23, 9906.45it/s]\u001b[A\n",
            " 34%|███▍      | 120103/351122 [00:11<00:22, 10284.65it/s]\u001b[A\n",
            " 35%|███▍      | 121140/351122 [00:11<00:22, 10300.85it/s]\u001b[A\n",
            " 35%|███▍      | 122290/351122 [00:12<00:21, 10630.15it/s]\u001b[A\n",
            " 35%|███▌      | 123394/351122 [00:12<00:21, 10748.71it/s]\u001b[A\n",
            " 35%|███▌      | 124474/351122 [00:12<00:21, 10696.01it/s]\u001b[A\n",
            " 36%|███▌      | 125603/351122 [00:12<00:20, 10864.90it/s]\u001b[A\n",
            " 36%|███▌      | 126717/351122 [00:12<00:20, 10943.79it/s]\u001b[A\n",
            " 36%|███▋      | 127814/351122 [00:12<00:20, 10885.63it/s]\u001b[A\n",
            " 37%|███▋      | 128905/351122 [00:12<00:21, 10377.66it/s]\u001b[A\n",
            " 37%|███▋      | 129952/351122 [00:12<00:21, 10403.11it/s]\u001b[A\n",
            " 37%|███▋      | 131063/351122 [00:12<00:20, 10604.00it/s]\u001b[A\n",
            " 38%|███▊      | 132139/351122 [00:12<00:20, 10648.00it/s]\u001b[A\n",
            " 38%|███▊      | 133266/351122 [00:13<00:20, 10825.97it/s]\u001b[A\n",
            " 38%|███▊      | 134367/351122 [00:13<00:19, 10879.98it/s]\u001b[A\n",
            " 39%|███▊      | 135457/351122 [00:13<00:20, 10734.83it/s]\u001b[A\n",
            " 39%|███▉      | 136573/351122 [00:13<00:19, 10858.59it/s]\u001b[A\n",
            " 39%|███▉      | 137704/351122 [00:13<00:19, 10988.43it/s]\u001b[A\n",
            " 40%|███▉      | 138821/351122 [00:13<00:19, 11038.73it/s]\u001b[A\n",
            " 40%|███▉      | 139926/351122 [00:13<00:19, 10890.29it/s]\u001b[A\n",
            " 40%|████      | 141017/351122 [00:13<00:19, 10683.65it/s]\u001b[A\n",
            " 40%|████      | 142088/351122 [00:13<00:19, 10520.68it/s]\u001b[A\n",
            " 41%|████      | 143148/351122 [00:14<00:19, 10543.23it/s]\u001b[A\n",
            " 41%|████      | 144235/351122 [00:14<00:19, 10639.00it/s]\u001b[A\n",
            " 41%|████▏     | 145309/351122 [00:14<00:19, 10668.00it/s]\u001b[A\n",
            " 42%|████▏     | 146463/351122 [00:14<00:18, 10914.41it/s]\u001b[A\n",
            " 42%|████▏     | 147559/351122 [00:14<00:18, 10926.46it/s]\u001b[A\n",
            " 42%|████▏     | 148654/351122 [00:14<00:19, 10453.30it/s]\u001b[A\n",
            " 43%|████▎     | 149705/351122 [00:14<00:19, 10202.50it/s]\u001b[A\n",
            " 43%|████▎     | 150766/351122 [00:14<00:19, 10319.38it/s]\u001b[A\n",
            " 43%|████▎     | 151889/351122 [00:14<00:18, 10574.78it/s]\u001b[A\n",
            " 44%|████▎     | 153028/351122 [00:14<00:18, 10805.29it/s]\u001b[A\n",
            " 44%|████▍     | 154113/351122 [00:15<00:18, 10812.23it/s]\u001b[A\n",
            " 44%|████▍     | 155198/351122 [00:15<00:18, 10822.66it/s]\u001b[A\n",
            " 45%|████▍     | 156342/351122 [00:15<00:17, 11000.09it/s]\u001b[A\n",
            " 45%|████▍     | 157451/351122 [00:15<00:17, 11024.38it/s]\u001b[A\n",
            " 45%|████▌     | 158572/351122 [00:15<00:17, 11077.88it/s]\u001b[A\n",
            " 45%|████▌     | 159704/351122 [00:15<00:17, 11147.15it/s]\u001b[A\n",
            " 46%|████▌     | 160843/351122 [00:15<00:16, 11217.26it/s]\u001b[A\n",
            " 46%|████▌     | 161985/351122 [00:15<00:16, 11276.19it/s]\u001b[A\n",
            " 46%|████▋     | 163114/351122 [00:15<00:17, 10877.14it/s]\u001b[A\n",
            " 47%|████▋     | 164206/351122 [00:15<00:17, 10839.71it/s]\u001b[A\n",
            " 47%|████▋     | 165293/351122 [00:16<00:17, 10683.80it/s]\u001b[A\n",
            " 47%|████▋     | 166364/351122 [00:16<00:17, 10434.80it/s]\u001b[A\n",
            " 48%|████▊     | 167411/351122 [00:16<00:18, 9791.19it/s] \u001b[A\n",
            " 48%|████▊     | 168505/351122 [00:16<00:18, 10107.83it/s]\u001b[A\n",
            " 48%|████▊     | 169526/351122 [00:16<00:18, 9928.27it/s] \u001b[A\n",
            " 49%|████▊     | 170655/351122 [00:16<00:17, 10300.51it/s]\u001b[A\n",
            " 49%|████▉     | 171801/351122 [00:16<00:16, 10621.05it/s]\u001b[A\n",
            " 49%|████▉     | 172947/351122 [00:16<00:16, 10858.55it/s]\u001b[A\n",
            " 50%|████▉     | 174041/351122 [00:16<00:16, 10577.29it/s]\u001b[A\n",
            " 50%|████▉     | 175106/351122 [00:17<00:16, 10550.44it/s]\u001b[A\n",
            " 50%|█████     | 176166/351122 [00:17<00:16, 10315.98it/s]\u001b[A\n",
            " 50%|█████     | 177203/351122 [00:17<00:16, 10280.76it/s]\u001b[A\n",
            " 51%|█████     | 178274/351122 [00:17<00:16, 10405.68it/s]\u001b[A\n",
            " 51%|█████     | 179318/351122 [00:17<00:16, 10385.09it/s]\u001b[A\n",
            " 51%|█████▏    | 180398/351122 [00:17<00:16, 10502.95it/s]\u001b[A\n",
            " 52%|█████▏    | 181450/351122 [00:17<00:16, 10308.87it/s]\u001b[A\n",
            " 52%|█████▏    | 182512/351122 [00:17<00:16, 10398.26it/s]\u001b[A\n",
            " 52%|█████▏    | 183557/351122 [00:17<00:16, 10411.52it/s]\u001b[A\n",
            " 53%|█████▎    | 184600/351122 [00:17<00:16, 10334.54it/s]\u001b[A\n",
            " 53%|█████▎    | 185635/351122 [00:18<00:16, 10304.55it/s]\u001b[A\n",
            " 53%|█████▎    | 186667/351122 [00:18<00:16, 10175.88it/s]\u001b[A\n",
            " 53%|█████▎    | 187686/351122 [00:18<00:16, 9774.97it/s] \u001b[A\n",
            " 54%|█████▍    | 188731/351122 [00:18<00:16, 9967.20it/s]\u001b[A\n",
            " 54%|█████▍    | 189732/351122 [00:18<00:16, 9736.98it/s]\u001b[A\n",
            " 54%|█████▍    | 190858/351122 [00:18<00:15, 10146.69it/s]\u001b[A\n",
            " 55%|█████▍    | 191997/351122 [00:18<00:15, 10488.59it/s]\u001b[A\n",
            " 55%|█████▍    | 193084/351122 [00:18<00:14, 10598.19it/s]\u001b[A\n",
            " 55%|█████▌    | 194239/351122 [00:18<00:14, 10865.18it/s]\u001b[A\n",
            " 56%|█████▌    | 195332/351122 [00:18<00:14, 10469.16it/s]\u001b[A\n",
            " 56%|█████▌    | 196387/351122 [00:19<00:15, 10236.86it/s]\u001b[A\n",
            " 56%|█████▌    | 197417/351122 [00:19<00:15, 10203.46it/s]\u001b[A\n",
            " 57%|█████▋    | 198442/351122 [00:19<00:14, 10193.84it/s]\u001b[A\n",
            " 57%|█████▋    | 199587/351122 [00:19<00:14, 10540.06it/s]\u001b[A\n",
            " 57%|█████▋    | 200647/351122 [00:19<00:14, 10395.15it/s]\u001b[A\n",
            " 57%|█████▋    | 201691/351122 [00:19<00:14, 10344.28it/s]\u001b[A\n",
            " 58%|█████▊    | 202749/351122 [00:19<00:14, 10412.94it/s]\u001b[A\n",
            " 58%|█████▊    | 203793/351122 [00:19<00:14, 9999.01it/s] \u001b[A\n",
            " 58%|█████▊    | 204920/351122 [00:19<00:14, 10347.43it/s]\u001b[A\n",
            " 59%|█████▊    | 205991/351122 [00:20<00:13, 10453.34it/s]\u001b[A\n",
            " 59%|█████▉    | 207042/351122 [00:20<00:14, 10014.16it/s]\u001b[A\n",
            " 59%|█████▉    | 208098/351122 [00:20<00:14, 10170.71it/s]\u001b[A\n",
            " 60%|█████▉    | 209190/351122 [00:20<00:13, 10384.15it/s]\u001b[A\n",
            " 60%|█████▉    | 210341/351122 [00:20<00:13, 10697.70it/s]\u001b[A\n",
            " 60%|██████    | 211443/351122 [00:20<00:12, 10790.30it/s]\u001b[A\n",
            " 61%|██████    | 212592/351122 [00:20<00:12, 10990.32it/s]\u001b[A\n",
            " 61%|██████    | 213695/351122 [00:20<00:12, 10992.78it/s]\u001b[A\n",
            " 61%|██████    | 214843/351122 [00:20<00:12, 11133.40it/s]\u001b[A\n",
            " 62%|██████▏   | 215972/351122 [00:20<00:12, 11179.69it/s]\u001b[A\n",
            " 62%|██████▏   | 217095/351122 [00:21<00:11, 11194.72it/s]\u001b[A\n",
            " 62%|██████▏   | 218216/351122 [00:21<00:12, 10633.51it/s]\u001b[A\n",
            " 62%|██████▏   | 219287/351122 [00:21<00:12, 10621.19it/s]\u001b[A\n",
            " 63%|██████▎   | 220354/351122 [00:21<00:12, 10454.17it/s]\u001b[A\n",
            " 63%|██████▎   | 221404/351122 [00:21<00:12, 10108.24it/s]\u001b[A\n",
            " 63%|██████▎   | 222474/351122 [00:21<00:12, 10276.72it/s]\u001b[A\n",
            " 64%|██████▎   | 223548/351122 [00:21<00:12, 10409.51it/s]\u001b[A\n",
            " 64%|██████▍   | 224660/351122 [00:21<00:11, 10612.32it/s]\u001b[A\n",
            " 64%|██████▍   | 225725/351122 [00:21<00:11, 10474.57it/s]\u001b[A\n",
            " 65%|██████▍   | 226776/351122 [00:21<00:12, 10245.11it/s]\u001b[A\n",
            " 65%|██████▍   | 227804/351122 [00:22<00:12, 10188.89it/s]\u001b[A\n",
            " 65%|██████▌   | 228826/351122 [00:22<00:12, 9940.18it/s] \u001b[A\n",
            " 65%|██████▌   | 229823/351122 [00:22<00:12, 9902.81it/s]\u001b[A\n",
            " 66%|██████▌   | 230835/351122 [00:22<00:12, 9963.51it/s]\u001b[A\n",
            " 66%|██████▌   | 231873/351122 [00:22<00:11, 10083.79it/s]\u001b[A\n",
            " 66%|██████▋   | 232883/351122 [00:22<00:12, 9638.32it/s] \u001b[A\n",
            " 67%|██████▋   | 233975/351122 [00:22<00:11, 9989.06it/s]\u001b[A\n",
            " 67%|██████▋   | 235061/351122 [00:22<00:11, 10232.82it/s]\u001b[A\n",
            " 67%|██████▋   | 236091/351122 [00:22<00:11, 10114.98it/s]\u001b[A\n",
            " 68%|██████▊   | 237110/351122 [00:23<00:11, 10137.32it/s]\u001b[A\n",
            " 68%|██████▊   | 238128/351122 [00:23<00:11, 9646.06it/s] \u001b[A\n",
            " 68%|██████▊   | 239100/351122 [00:23<00:12, 8763.17it/s]\u001b[A\n",
            " 68%|██████▊   | 239997/351122 [00:23<00:12, 8678.41it/s]\u001b[A\n",
            " 69%|██████▊   | 240880/351122 [00:23<00:12, 8564.65it/s]\u001b[A\n",
            " 69%|██████▉   | 241748/351122 [00:23<00:12, 8517.04it/s]\u001b[A\n",
            " 69%|██████▉   | 242608/351122 [00:23<00:12, 8533.30it/s]\u001b[A\n",
            " 69%|██████▉   | 243482/351122 [00:23<00:12, 8592.19it/s]\u001b[A\n",
            " 70%|██████▉   | 244345/351122 [00:23<00:12, 8578.23it/s]\u001b[A\n",
            " 70%|██████▉   | 245206/351122 [00:23<00:12, 8584.98it/s]\u001b[A\n",
            " 70%|███████   | 246213/351122 [00:24<00:11, 8982.20it/s]\u001b[A\n",
            " 70%|███████   | 247197/351122 [00:24<00:11, 9221.35it/s]\u001b[A\n",
            " 71%|███████   | 248250/351122 [00:24<00:10, 9578.42it/s]\u001b[A\n",
            " 71%|███████   | 249284/351122 [00:24<00:10, 9792.64it/s]\u001b[A\n",
            " 71%|███████▏  | 250276/351122 [00:24<00:10, 9829.34it/s]\u001b[A\n",
            " 72%|███████▏  | 251426/351122 [00:24<00:09, 10276.77it/s]\u001b[A\n",
            " 72%|███████▏  | 252530/351122 [00:24<00:09, 10493.82it/s]\u001b[A\n",
            " 72%|███████▏  | 253587/351122 [00:24<00:09, 10304.48it/s]\u001b[A\n",
            " 73%|███████▎  | 254724/351122 [00:24<00:09, 10601.91it/s]\u001b[A\n",
            " 73%|███████▎  | 255791/351122 [00:24<00:09, 10422.05it/s]\u001b[A\n",
            " 73%|███████▎  | 256846/351122 [00:25<00:09, 10457.57it/s]\u001b[A\n",
            " 73%|███████▎  | 257896/351122 [00:25<00:08, 10429.38it/s]\u001b[A\n",
            " 74%|███████▎  | 258942/351122 [00:25<00:08, 10291.53it/s]\u001b[A\n",
            " 74%|███████▍  | 259974/351122 [00:25<00:09, 9966.62it/s] \u001b[A\n",
            " 74%|███████▍  | 261048/351122 [00:25<00:08, 10186.47it/s]\u001b[A\n",
            " 75%|███████▍  | 262169/351122 [00:25<00:08, 10472.67it/s]\u001b[A\n",
            " 75%|███████▍  | 263303/351122 [00:25<00:08, 10716.38it/s]\u001b[A\n",
            " 75%|███████▌  | 264446/351122 [00:25<00:07, 10918.95it/s]\u001b[A\n",
            " 76%|███████▌  | 265583/351122 [00:25<00:07, 11050.43it/s]\u001b[A\n",
            " 76%|███████▌  | 266692/351122 [00:26<00:07, 10959.94it/s]\u001b[A\n",
            " 76%|███████▋  | 267838/351122 [00:26<00:07, 11102.49it/s]\u001b[A\n",
            " 77%|███████▋  | 268953/351122 [00:26<00:07, 11115.18it/s]\u001b[A\n",
            " 77%|███████▋  | 270067/351122 [00:26<00:07, 11055.60it/s]\u001b[A\n",
            " 77%|███████▋  | 271174/351122 [00:26<00:07, 11017.67it/s]\u001b[A\n",
            " 78%|███████▊  | 272277/351122 [00:26<00:07, 10578.57it/s]\u001b[A\n",
            " 78%|███████▊  | 273340/351122 [00:26<00:07, 10468.82it/s]\u001b[A\n",
            " 78%|███████▊  | 274493/351122 [00:26<00:07, 10765.21it/s]\u001b[A\n",
            " 79%|███████▊  | 275642/351122 [00:26<00:06, 10971.88it/s]\u001b[A\n",
            " 79%|███████▉  | 276756/351122 [00:26<00:06, 11018.69it/s]\u001b[A\n",
            " 79%|███████▉  | 277861/351122 [00:27<00:06, 10908.69it/s]\u001b[A\n",
            " 79%|███████▉  | 278955/351122 [00:27<00:06, 10808.96it/s]\u001b[A\n",
            " 80%|███████▉  | 280038/351122 [00:27<00:06, 10513.71it/s]\u001b[A\n",
            " 80%|████████  | 281093/351122 [00:27<00:06, 10475.07it/s]\u001b[A\n",
            " 80%|████████  | 282180/351122 [00:27<00:06, 10589.14it/s]\u001b[A\n",
            " 81%|████████  | 283269/351122 [00:27<00:06, 10676.20it/s]\u001b[A\n",
            " 81%|████████  | 284367/351122 [00:27<00:06, 10764.69it/s]\u001b[A\n",
            " 81%|████████▏ | 285516/351122 [00:27<00:05, 10969.75it/s]\u001b[A\n",
            " 82%|████████▏ | 286615/351122 [00:27<00:05, 10918.20it/s]\u001b[A\n",
            " 82%|████████▏ | 287731/351122 [00:27<00:05, 10987.24it/s]\u001b[A\n",
            " 82%|████████▏ | 288832/351122 [00:28<00:05, 10992.20it/s]\u001b[A\n",
            " 83%|████████▎ | 289932/351122 [00:28<00:05, 10881.84it/s]\u001b[A\n",
            " 83%|████████▎ | 291021/351122 [00:28<00:05, 10528.18it/s]\u001b[A\n",
            " 83%|████████▎ | 292077/351122 [00:28<00:05, 10504.50it/s]\u001b[A\n",
            " 83%|████████▎ | 293130/351122 [00:28<00:05, 10359.60it/s]\u001b[A\n",
            " 84%|████████▍ | 294171/351122 [00:28<00:05, 10373.14it/s]\u001b[A\n",
            " 84%|████████▍ | 295238/351122 [00:28<00:05, 10458.96it/s]\u001b[A\n",
            " 84%|████████▍ | 296286/351122 [00:28<00:05, 10422.09it/s]\u001b[A\n",
            " 85%|████████▍ | 297379/351122 [00:28<00:05, 10566.03it/s]\u001b[A\n",
            " 85%|████████▌ | 298548/351122 [00:28<00:04, 10879.40it/s]\u001b[A\n",
            " 85%|████████▌ | 299702/351122 [00:29<00:04, 11067.69it/s]\u001b[A\n",
            " 86%|████████▌ | 300812/351122 [00:29<00:04, 10914.77it/s]\u001b[A\n",
            " 86%|████████▌ | 301907/351122 [00:29<00:04, 10609.79it/s]\u001b[A\n",
            " 86%|████████▋ | 303042/351122 [00:29<00:04, 10819.52it/s]\u001b[A\n",
            " 87%|████████▋ | 304163/351122 [00:29<00:04, 10931.27it/s]\u001b[A\n",
            " 87%|████████▋ | 305259/351122 [00:29<00:04, 10819.07it/s]\u001b[A\n",
            " 87%|████████▋ | 306344/351122 [00:29<00:04, 10712.84it/s]\u001b[A\n",
            " 88%|████████▊ | 307418/351122 [00:29<00:04, 10475.04it/s]\u001b[A\n",
            " 88%|████████▊ | 308524/351122 [00:29<00:04, 10642.14it/s]\u001b[A\n",
            " 88%|████████▊ | 309652/351122 [00:30<00:03, 10823.85it/s]\u001b[A\n",
            " 88%|████████▊ | 310737/351122 [00:30<00:03, 10777.42it/s]\u001b[A\n",
            " 89%|████████▉ | 311817/351122 [00:30<00:03, 10536.92it/s]\u001b[A\n",
            " 89%|████████▉ | 312874/351122 [00:30<00:03, 10337.02it/s]\u001b[A\n",
            " 89%|████████▉ | 313913/351122 [00:30<00:03, 10352.58it/s]\u001b[A\n",
            " 90%|████████▉ | 315034/351122 [00:30<00:03, 10594.61it/s]\u001b[A\n",
            " 90%|█████████ | 316105/351122 [00:30<00:03, 10628.52it/s]\u001b[A\n",
            " 90%|█████████ | 317210/351122 [00:30<00:03, 10749.80it/s]\u001b[A\n",
            " 91%|█████████ | 318298/351122 [00:30<00:03, 10786.07it/s]\u001b[A\n",
            " 91%|█████████ | 319378/351122 [00:30<00:03, 10541.40it/s]\u001b[A\n",
            " 91%|█████████▏| 320435/351122 [00:31<00:02, 10261.76it/s]\u001b[A\n",
            " 92%|█████████▏| 321465/351122 [00:31<00:03, 9851.24it/s] \u001b[A\n",
            " 92%|█████████▏| 322456/351122 [00:31<00:02, 9764.65it/s]\u001b[A\n",
            " 92%|█████████▏| 323456/351122 [00:31<00:02, 9834.04it/s]\u001b[A\n",
            " 92%|█████████▏| 324541/351122 [00:31<00:02, 10116.12it/s]\u001b[A\n",
            " 93%|█████████▎| 325685/351122 [00:31<00:02, 10478.47it/s]\u001b[A\n",
            " 93%|█████████▎| 326740/351122 [00:31<00:02, 10393.30it/s]\u001b[A\n",
            " 93%|█████████▎| 327784/351122 [00:31<00:02, 10384.82it/s]\u001b[A\n",
            " 94%|█████████▎| 328871/351122 [00:31<00:02, 10523.68it/s]\u001b[A\n",
            " 94%|█████████▍| 329982/351122 [00:31<00:01, 10691.32it/s]\u001b[A\n",
            " 94%|█████████▍| 331069/351122 [00:32<00:01, 10742.10it/s]\u001b[A\n",
            " 95%|█████████▍| 332146/351122 [00:32<00:01, 10206.63it/s]\u001b[A\n",
            " 95%|█████████▍| 333174/351122 [00:32<00:01, 10067.15it/s]\u001b[A\n",
            " 95%|█████████▌| 334186/351122 [00:32<00:01, 9961.99it/s] \u001b[A\n",
            " 95%|█████████▌| 335224/351122 [00:32<00:01, 10081.72it/s]\u001b[A\n",
            " 96%|█████████▌| 336325/351122 [00:32<00:01, 10341.96it/s]\u001b[A\n",
            " 96%|█████████▌| 337396/351122 [00:32<00:01, 10449.40it/s]\u001b[A\n",
            " 96%|█████████▋| 338485/351122 [00:32<00:01, 10576.17it/s]\u001b[A\n",
            " 97%|█████████▋| 339610/351122 [00:32<00:01, 10768.77it/s]\u001b[A\n",
            " 97%|█████████▋| 340690/351122 [00:32<00:00, 10765.76it/s]\u001b[A\n",
            " 97%|█████████▋| 341769/351122 [00:33<00:00, 10697.44it/s]\u001b[A\n",
            " 98%|█████████▊| 342873/351122 [00:33<00:00, 10795.94it/s]\u001b[A\n",
            " 98%|█████████▊| 343981/351122 [00:33<00:00, 10877.14it/s]\u001b[A\n",
            " 98%|█████████▊| 345070/351122 [00:33<00:00, 10653.98it/s]\u001b[A\n",
            " 99%|█████████▊| 346138/351122 [00:33<00:00, 10527.77it/s]\u001b[A\n",
            " 99%|█████████▉| 347281/351122 [00:33<00:00, 10781.65it/s]\u001b[A\n",
            " 99%|█████████▉| 348420/351122 [00:33<00:00, 10955.49it/s]\u001b[A\n",
            "100%|█████████▉| 349519/351122 [00:33<00:00, 10300.09it/s]\u001b[A\n",
            "100%|█████████▉| 350581/351122 [00:33<00:00, 10393.89it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1単語を表現する次元数： 300\n",
            "単語数： 351122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYuQW1m_ag-x",
        "colab_type": "code",
        "outputId": "6178225c-095b-4820-ae72-17bc2d998262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "# ベクトル化したバージョンのボキャブラリーを作成します\n",
        "TEXT.build_vocab(train_ds, vectors=japanese_fasttext_vectors, min_freq=1)\n",
        "\n",
        "# ボキャブラリーのベクトルを確認します\n",
        "print(TEXT.vocab.vectors.shape)  # 52個の単語が300次元のベクトルで表現されている\n",
        "TEXT.vocab.vectors\n",
        "\n",
        "# ボキャブラリーの単語の順番を確認します\n",
        "TEXT.vocab.stoi\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([49, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'0': 18,\n",
              "             '<pad>': 1,\n",
              "             '<unk>': 0,\n",
              "             '、': 7,\n",
              "             '。': 3,\n",
              "             'い': 19,\n",
              "             'いる': 11,\n",
              "             'か': 12,\n",
              "             'から': 20,\n",
              "             'が': 8,\n",
              "             'し': 9,\n",
              "             'する': 21,\n",
              "             'その': 22,\n",
              "             'た': 23,\n",
              "             'て': 13,\n",
              "             'で': 24,\n",
              "             'です': 25,\n",
              "             'と': 2,\n",
              "             'な': 4,\n",
              "             'に': 26,\n",
              "             'に対して': 27,\n",
              "             'の': 5,\n",
              "             'は': 28,\n",
              "             'まし': 29,\n",
              "             'ます': 14,\n",
              "             'を': 10,\n",
              "             'クラス': 30,\n",
              "             'ネガティブ': 31,\n",
              "             'ポジティブ': 32,\n",
              "             'モデル': 33,\n",
              "             'レビュー': 34,\n",
              "             '値': 35,\n",
              "             '分類': 15,\n",
              "             '取り組み': 36,\n",
              "             '商品': 37,\n",
              "             '女性': 38,\n",
              "             '女王': 39,\n",
              "             '好き': 40,\n",
              "             '姫': 41,\n",
              "             '文章': 6,\n",
              "             '本章': 16,\n",
              "             '構築': 42,\n",
              "             '機械学習': 43,\n",
              "             '王': 44,\n",
              "             '王子': 45,\n",
              "             '男性': 46,\n",
              "             '短い': 47,\n",
              "             '自然言語処理': 48,\n",
              "             '評価': 17})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgR5gme_ag-1",
        "colab_type": "code",
        "outputId": "1ce2e8e5-9575-46b1-b1c3-ad98b0b10df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# 姫 - 女性 + 男性 のベクトルがどれと似ているのか確認してみます\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 姫 - 女性 + 男性\n",
        "tensor_calc = TEXT.vocab.vectors[41] - \\\n",
        "    TEXT.vocab.vectors[38] + TEXT.vocab.vectors[46]\n",
        "\n",
        "# コサイン類似度を計算\n",
        "# dim=0 は0次元目で計算してくださいという指定\n",
        "print(\"女王\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[39], dim=0))\n",
        "print(\"王\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[44], dim=0))\n",
        "print(\"王子\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[45], dim=0))\n",
        "print(\"機械学習\", F.cosine_similarity(tensor_calc, TEXT.vocab.vectors[43], dim=0))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "女王 tensor(0.3650)\n",
            "王 tensor(0.3461)\n",
            "王子 tensor(0.5531)\n",
            "機械学習 tensor(0.0952)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7hdHOdHag-4",
        "colab_type": "text"
      },
      "source": [
        "姫 - 女性 + 男性　を計算すると狙った通り、王子がもっとも近い結果になりました"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpNTBkEHag-6",
        "colab_type": "text"
      },
      "source": [
        "以上"
      ]
    }
  ]
}